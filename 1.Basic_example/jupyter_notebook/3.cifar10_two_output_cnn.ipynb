{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 output CNN\n",
    "\n",
    "In this section, we are going to construct convolutional neural network (CNN) with 2 output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dependencies\n",
    "\n",
    "First, we can load tf.keras and other python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow version is 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2 ** 10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"[INFO] Tensorflow version is {}\".format(tf.__version__))\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load dataset and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train is (50000, 32, 32, 3)\n",
      "Shape of x_test is (10000, 32, 32, 3)\n",
      "Shape of y_train is (50000, 10)\n",
      "Shape of y_test is (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load cifar10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Pre-processing\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_train /= 255.\n",
    "x_test /= 255.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10).astype(np.float32)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10).astype(np.float32)\n",
    "\n",
    "print(\"Shape of x_train is {}\".format(np.shape(x_train)))\n",
    "print(\"Shape of x_test is {}\".format(np.shape(x_test)))\n",
    "print(\"Shape of y_train is {}\".format(np.shape(y_train)))\n",
    "print(\"Shape of y_test is {}\".format(np.shape(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construct 2 output CNN with `tf.keras`.\n",
    "\n",
    "We design a network for two purposes.\n",
    "\n",
    "One is for reconstruction purpose, the next one is for classification purpose network.\n",
    "\n",
    "For these two purposes, we design a shared encoder network, a decoder for reconstruction, and an fc layer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   18496       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4096)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          524416      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 8, 8, 16)     9232        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 16)   0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 10)           650         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Conv2DTranspose)      (None, 32, 32, 3)    435         up_sampling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 562,381\n",
      "Trainable params: 562,381\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Total parameters of model is 562381\n",
      "model output is [<DeferredTensor 'None' shape=(?, 10) dtype=float32>, <DeferredTensor 'None' shape=(?, 32, 32, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Build a tf.keras model\n",
    "\n",
    "# 1) Encoder layer for feature extraction\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, \n",
    "                               kernel_initializer=\"he_normal\",\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
    "                               padding=\"same\", activation=tf.nn.relu)(inputs)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, \n",
    "                               kernel_initializer=\"he_normal\",\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
    "                               padding=\"same\", activation=tf.nn.relu)(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(conv2)\n",
    "\n",
    "# 2) Decoder layer for reconstruction\n",
    "trans_conv1 = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3,\n",
    "                                    kernel_initializer=\"he_normal\",\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
    "                                    strides=1, padding=\"same\",\n",
    "                                    activation=tf.nn.relu)(pool2)\n",
    "unpool1 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(trans_conv1)\n",
    "trans_conv2 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3,\n",
    "                                    kernel_initializer=\"he_normal\",\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
    "                                    strides=1, padding=\"same\",\n",
    "                                    activation=tf.nn.relu)(unpool1)\n",
    "unpool2 = tf.keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(trans_conv2)\n",
    "reconstruction = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=3,\n",
    "                                    kernel_initializer=\"he_normal\",\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(5e-4),\n",
    "                                    strides=2, padding=\"same\",\n",
    "                                    activation=tf.nn.sigmoid, name=\"output_2\")(unpool1)\n",
    "\n",
    "# 3) Fc layer for classification\n",
    "flatten = tf.keras.layers.Flatten()(pool2)\n",
    "fc1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)(flatten)\n",
    "fc2 = tf.keras.layers.Dense(64, activation=tf.nn.relu)(fc1)\n",
    "probabilities = tf.keras.layers.Dense(10, activation=tf.nn.softmax, name=\"output_1\")(fc2)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[probabilities, reconstruction])\n",
    "model.summary()\n",
    "print(\"Total parameters of model is {}\".format(model.count_params()))  #468984\n",
    "print(\"model output is {}\".format(model.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.0001)\n",
    "model.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "              optimizer=opt, loss_weights=[1., 0.05],\n",
    "              metrics=[\"accuracy\", \"mse\"])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_SIZE = 10000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dataset pipeline\n",
    "\n",
    "**The following is the most important part of this section.**\n",
    "\n",
    "Basically we use `tf.data`, but we build custom data pipeline to match the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for dataset pipeline\n",
    "def _input_fn(x, y):\n",
    "\n",
    "    # Custom dataset loader for 2 output network\n",
    "    def generator():\n",
    "        for images, labels in zip(x, y):\n",
    "            yield images, {\"output_1\": labels, \"output_2\": images}\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=(tf.float32, {\"output_1\": tf.float32, \"output_2\": tf.float32}))\n",
    "    dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train model\n",
    "\n",
    "Finally, train our model for checking accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\t Loss: #2.454409599304199\tAccuracy: #0.046875\n",
      "Epoch #2\t Loss: #2.4976654052734375\tAccuracy: #0.109375\n",
      "Epoch #3\t Loss: #2.2861523628234863\tAccuracy: #0.171875\n",
      "Epoch #4\t Loss: #2.3842673301696777\tAccuracy: #0.078125\n",
      "Epoch #5\t Loss: #2.373509645462036\tAccuracy: #0.109375\n",
      "Epoch #6\t Loss: #2.363190174102783\tAccuracy: #0.140625\n",
      "Epoch #7\t Loss: #2.413235902786255\tAccuracy: #0.078125\n",
      "Epoch #8\t Loss: #2.3201699256896973\tAccuracy: #0.125\n",
      "Epoch #9\t Loss: #2.5095200538635254\tAccuracy: #0.078125\n",
      "Epoch #10\t Loss: #2.501054525375366\tAccuracy: #0.09375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss, prediction_loss, recon_loss, \\\n",
    "    prediction_acc, _, _, recon_error = model.train_on_batch(_input_fn(x_train, y_train))\n",
    "    _, test_loss, _, test_acc, _, _, _ = model.test_on_batch(_input_fn(x_test, y_test))\n",
    "    print('Epoch #{}\\t Loss: #{}\\tAccuracy: #{}'.format(epoch + 1, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
